2017-01-09 Dev and production accounts
We have a working sandbox, http://ves-hx-78.ebi.ac.uk:12000/index.html, (not fully functional but a good start) and a working dev Solr. Not knowing how our production / dev filesystems are going to work is going to hold us back.

Issues:

- When will the new GPFS backed filesystems (eg /nfs/public/release) be available for us to use on our production web servers ?

- To populate these filesystems we will need them mounted on a dev machine - by that I mean one that is not used in production. How can we do this ?

- Who will provide our dev web servers - www-prod or another team ?

- What file systems will be available on our dev servers ? As well as read access to /nfs/public/release etc we will need dev areas equivalent to these




2016-11-21 Virtual user for administrating ensembl website database files
Will be done this week:
ensdb-prod - copies within the group mysql-ens*prod* and mysql-ens-sta*
ensdb-web - mysql-ens-sta* and mysql-ens-web*
ensdb-pub - mysql-ens-sta* and mysql-ens*pub*

2016-11-18 Priorities for delivering Web MySQL servers
Highest priority: accounts, sessions, tools and the various ensembldb instances

After that, the five 'species&compara'. 

Having these first will be most usefull for us in developing our deployment procedures and also for setting up the internal load balancing 

Timelines:

accounts, sessions, tools, ensembldb - before Xmas

remainder (minus two) - end of Jan

final two (mysql-ens-web-archive and mysql-ens-web-archive-mart) - April 

2016-11-17 Planning for delivering batch of Web MySQL servers
species/compara, mart, grch37/mart, private, pre, archive

2016-11-14 Updates from Steve

- We cannot have a dev VM with our new home and storage areas mounted on it for 'some weeks'. We could have one with the old areas now though. We really really need to get going on this so it'd be good if we could use the old areas and get building localsw ASAP. Q - are there any existing accounts that we could use for this ?

- We have an FTP site at EBI and now need to test a mirror server for FUSE.

- RT ticket about Solr. Major point is that, like the web VMs, if we want to use the new storage areas we will need to wait. I think we should wait.

- Request for info about our LSF setup has been be moved to System Infrastructure.

- Not heard anything about how we should be using our gold storage. 

2016-11-11 Andy requests for update with web prod
i) *Very important*. Traffic manager entries for Embassy (#98380) - has been going along OK but I've no confirmation that we're good to go next week.

(ii) web dev VM (originally #98774 with sysinf, now in email with Simone and Andrea)
There are two types of storage to consider here. The existing one, which is obviously in production and ready and the new, untested GPFS storage that is being configured. Using the latter is going to take longer than using the former. Web prod cannot re-prioritise this.

Web team to progress with the current storage solution and aim to have our production system on the new GPFS system.

(iii) Review our requirements with them so that we can rethink our plans if necc. #98549 and #98831. Also emailed Rich Boyce directly about gold disc. 

(iv) Request the rest of the VMs. The highest priority ones will be those for the most complex services; can't give a hit list until we've done (iii)


2016-10-27 Request for detail for restricted configuration
Right now we have the virtual user ensdb able to ssh/scp to ensmysql on the database servers, with no specific restriction on server. The sysadmin/network guys tells they can create an additional virtual user, with server restrictions, to allow the separation of Ens prod from web/public. 

They need from us:

1. virtual user names (ensprod plus ensweb or enspub perhaps?)

2. a list of database aliases for each virtual user, to restrict connections (presumably with overlap on the staging instances)

2016-10-19 Request for tc_ens02 Tomcat user (group ens_pub)

2016-10-18 Meeting with www-prod
Request for advice on set up.

What we need from our dev environment is:

(i) able to isolate our sandboxes from other developers (not happy with the idea of everyone having write access to my directory);

(ii) git push and pull (will require us to enter our passwords on every commit)

(iii) ability to customise login environments (require us to set environments with scripts, which again will be writable by everyone)

After the meeting, it was recognised that all the potential blockers aren't actually.
We'll get 30GB of local disk per VM and enough nfs storage which is ok until the middle of next year. 

Requesting for a virtual user for each developer (4/8 requested so far).


2016-10-07 Updates

- no progress on asking for production MySQL servers. Proposed to combine other / species.
- agreed with Production and DBAs to have just a single virtual user for database coping.
- no feedback from www-prod re load balancing for web MySQL servers
- written to www-prod asking for opinions on our proposed webserver topology 

Aims this week:

- request tc_ens01CC user so we can start on Solr
- request to www-prod asking about our proposed Solr topology
- start on tools
- copy data to dev instance


2016-10-03 Updates
Virtual users:
- ens_adm02 requested
- w3_ens02 requested
- tc_ens01CC (not requested yet)

All users have been minted with the ens_pub user group ((seemed easier than creating more, e.g. ensweb_pub)

Disc will be /nfs/public/r[o|w]/ensweb, not yet requested but will be made once the users have been confirmed 

All 86 databases are on ebi /nfs and we have a dev MySQL server with 4Tb disc that we can use to upgrade these to 5.6. This is however set up for the ensmysql user (as used by production) but we are not sure if we can have our own user which would seem like the sensible thing to do. We have a meeting on Friday to discuss this with the DBAs and other TSC 

Asked www-prod about how the loadbalancer would work for our database (public MySQL and website)

Near to asking for production MySQL servers to be deployed. Still to tie down virtual users and decide how we split databases - do we stick with species/other split, or do we combine the two and have more servers for each? We have never seen high load on the compara database.

2016-09-27 Project space and users request still on hold. Group needs to be set up
Currently ens_pub and it's owned by Paul Kersey. We really want machines up asap. Spoken to Paul K and he's happy with some transfers of ownership.

If we want all new things separate we might ask for users:
ensweb_adm, w3_ensweb01, tc_ensweb01

But before doing that you should ask for the group ensweb_pub

The group can't be requested through the web interface 
so we might need to contact desktop directly.

After the group is created you might request the users and then the the 
storage area.

2016-09-22 Request for two virtual users and project space for the e! website at EBI.
admin user: ensweb_adm
web user: w3_ensweb01
group: ensweb_pub
Read only project space: /nfs/public/ro/ensweb
Read/write project space: /nfs/public/rw/ensweb

Update: ens_adm02 and w3_ens02 to keep the same name style with the numbers being the first available ones.

2016-09-16 Web topology agreement
This has been discussed at a meeting between TSC and the web team about EBI deployment. The focus was fitting into existing practice and figuring out where special cases will occur and flagging for further investigation. 

More details on a dedicated page on Ensembl web confluence space
https://www.ebi.ac.uk/seqdb/confluence/display/ENSWEB/Website+topology

2016-09-08 Request for web dev environment

1) /nfs space for ensemblweb, both rw and ro
2) A virtual user (not needed for the sandboxes of course, but this should be the owner of the /nfs volumes)
3) A shared group for webteam members and the virtual users

This is better talked to TSC leaders, meeting next Tuesday (13/09).
Steve hangs off requesting sanbox VMs
